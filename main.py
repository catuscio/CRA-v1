import streamlit as st

from langchain_core.messages.chat import ChatMessage
from langchain_core.output_parsers import StrOutputParser
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.callbacks.tracers.langchain import LangChainTracer
tracer = LangChainTracer(project_name="CRA")

from load_prompts import load_prompt
from major_selection import major_selection
from rag_process import rag_process

from dotenv import load_dotenv
load_dotenv()


#---------------------------------#
#-------- Deploy Settings --------#
#---------------------------------#
# __import__('pysqlite3')
# import sys
# import pysqlite3
# sys.modules['sqlite3'] = sys.modules["pysqlite3"]

# from google.oauth2 import service_account
# import google.generativeai as genai  # genai import ì¶”ê°€

# # Create API client.
# credentials = service_account.Credentials.from_service_account_info(
#     st.secrets["gcp_service_account"],
# )

# # Gemini êµ¬ì„±
# genai.configure(
#     credentials=credentials,
#)
###################################


#---------------------------------#
#---------- UI Settings ----------#
#---------------------------------#
st.title("ğŸ“Œìˆ˜ê°•í¸ëŒ ë„ìš°ë¯¸âœ¨")

# sidebar
with st.sidebar :
    # clear dialouge
    clear_btn = st.button("ëŒ€í™” ì´ˆê¸°í™”")
    # í•™ë²ˆ ì…ë ¥
    id = st.number_input(
        "í•™ë²ˆ", step=1, max_value=25, min_value=17
    )
    # ì†Œì† ë‹¨ê³¼ëŒ€ ì…ë ¥
    dept = st.selectbox(
        "ì†Œì† ëŒ€í•™",
        ("ì¸ë¬¸ê³¼í•™ëŒ€",
         "ì‚¬íšŒê³¼í•™ëŒ€",
         "ê²½ì˜ê²½ì œëŒ€",
         "í˜¸í…”ê´€ê´‘ëŒ€",
         "ìì—°ê³¼í•™ëŒ€",
         "ìƒëª…ê³¼í•™ëŒ€",
         "ì¸ê³µì§€ëŠ¥ìœµí•©ëŒ€",
         "ê³µê³¼ëŒ€",
         "ì˜ˆì²´ëŠ¥ëŒ€")
    )
    # ì „ê³µ ì…ë ¥
    major = st.selectbox("ì „ê³µ", options=major_selection(dept))
    semester = st.select_slider(
        "ì¬í•™ í•™ê¸°",
        ["ì‹ ì…ìƒ",
         "1í•™ë…„",
         "2í•™ë…„",
         "3í•™ë…„",
         "4í•™ë…„",
         "5í•™ë…„",
         "ì´ˆê³¼í•™ê¸°"])
    # í¸ì… ì—¬ë¶€ ì…ë ¥
    bool_transfer = st.checkbox("í¸ì…")

# stuInfo
stuInfo = f"""
#í•™ìƒì •ë³´\n
ì…í•™ë…„ë„: {id}\n
ì†Œì†ëŒ€í•™: {dept}\n
ì „ê³µ: {major}\n
ì¬í•™ í•™ê¸°ê¸°: {semester}\n
í¸ì…ì—¬ë¶€: {bool_transfer}
"""


#---------------------------------#
#-------- Message Storing --------#
#---------------------------------#
# dialouge storage
if "messages" not in st.session_state :
    st.session_state["messages"] = []

# add new message to storage
def add_message(role, message) :
    st.session_state["messages"].append(ChatMessage(role=role, content=message))

# print all dialouge
def print_messages() :
    for chat_message in st.session_state["messages"] :
        st.chat_message(chat_message.role).write(chat_message.content)


#---------------------------------#
#------------- Chain -------------#
#---------------------------------#
def create_chain() :
    # prompt
    prompt = load_prompt("prompts/basic.yaml", encoding="cp949")

    # model - ì¸ì¦ì •ë³´ ì¶”ê°€
    llm = ChatGoogleGenerativeAI(
        model="gemini-1.5-flash",
        temperature=0,
        #credentials=credentials
    )

    # output parser
    output_parser = StrOutputParser()

    # chain
    chain = (
        {"context": rag_process,
         "question": RunnablePassthrough(),
         "stuInfo": lambda x: stuInfo}
        | prompt
        | llm
        | output_parser
    )

    return chain   


#---------------------------------#
#---------- User Action ----------#
#---------------------------------#
if clear_btn:
    st.session_state["messages"] = []
print_messages()

# user input
user_input = st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì„¸ìš”!")

# if input
if user_input :
    # user input
    st.chat_message("user").write(user_input)

    # chain
    chain = create_chain()

    # chain call
    response = chain.stream(user_input)
    with st.chat_message("assistant"):
        # create empty container and print token by stream
        container = st.empty()
        ai_answer = ""
        for token in response :
            ai_answer += token
            container.markdown(ai_answer)

    # add dialougue to storage
    add_message("user", user_input)
    add_message("assistant", ai_answer)
